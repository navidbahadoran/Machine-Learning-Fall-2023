{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ccf5b0",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Navid Bahadoran</center>\n",
    "</h1>\n",
    "<h1>\n",
    "<center>Homework 8, due November 3rd, 11:59pm</center>\n",
    "</h1>\n",
    "\n",
    "<h2>\n",
    "<center>October 26, 2023</center>\n",
    "</h2>\n",
    "In this homework you are required to attach to your report the code that you implemented\n",
    "for each problem. If you use some code from the web, also mention in your\n",
    "report where you obtained the code from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d58ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display_markdown\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30405229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HMM parameters\n",
    "\n",
    "transition_probabilities = np.array([[0.95, 0.05],  # Transition from Fair to Fair, Loaded to Fair\n",
    "                                    [0.05, 0.95]]) # Transition from Fair to Loaded, Loaded to Loaded\n",
    "emission_probabilities = np.array([[1/6, 1/6, 1/6, 1/6, 1/6, 1/6],  # Emission probabilities for Fair\n",
    "                                [1/10, 1/10, 1/10, 1/10, 1/10, 1/2]])  # Emission probabilities for Loaded\n",
    "initial_probabilities = np.array([0.5, 0.5])  # Initial probabilities for Fair, Loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b52a5",
   "metadata": {},
   "source": [
    "**1. Download the dataset hmm_pb1.csv from Canvas. It represents a sequence of\n",
    "dice rolls x from the Dishonest casino model discussed in class. The model parameters\n",
    "are exactly those presented in class. The states of $Y$ are 1='Fair' and 2='Loaded’'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3594bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "hmm_pb1_path = Path(r'D:\\Pycharm\\Courses\\STA5635\\HW8\\hmm_pb1.csv')\n",
    "\n",
    "observed_sequence = np.array(pd.read_csv(hmm_pb1_path, header=None)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8362c",
   "metadata": {},
   "source": [
    "**a) Implement the Viterbi algorithm and find the most likely sequence y that generated\n",
    "the observed x. Use the log probabilities, as shown in the HMM slides from\n",
    "Canvas. Report the obtained sequence y of 1’s and 2’s for verification. (2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f0abbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The most probable sequence of the hidden state:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The most probable sequence of the hidden state:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Fair', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded', 'Loaded']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_states = 2\n",
    "T = len(observed_sequence)\n",
    "viterbi = np.zeros((num_states, T))\n",
    "backpointer = np.zeros((num_states, T), dtype=int)\n",
    "\n",
    "# Initialize the first column of the Viterbi matrix\n",
    "viterbi[:,0] = np.log(emission_probabilities[:, observed_sequence[0]-1]*initial_probabilities)\n",
    "# Perform the Viterbi algorithm\n",
    "for t in range(1, T):\n",
    "    max_prob=np.log(transition_probabilities)+viterbi[:,t-1].reshape(-1,1)\n",
    "    viterbi[:,t] = np.log(emission_probabilities[:,observed_sequence[t] - 1])+np.max(max_prob, axis = 0)\n",
    "    backpointer[:,t] = np.argmax(max_prob, axis = 0)\n",
    "\n",
    "# Find the most likely final state\n",
    "sequence_y = [np.argmax(viterbi[:, -1])]\n",
    "\n",
    "# # Backtrack to find the most likely sequence of states (y)\n",
    "for t in range(T - 1, 0, -1):\n",
    "\n",
    "    sequence_y.insert(0, backpointer[sequence_y[0], t])\n",
    "\n",
    "\n",
    "# # Print the obtained sequence y\n",
    "display_markdown(\"The most probable sequence of the hidden state:\", raw = True)\n",
    "print( [i+1 for i in sequence_y])\n",
    "display_markdown(\"The most probable sequence of the hidden state:\", raw = True)\n",
    "print( ['Fair' if state == 0 else 'Loaded' for state in sequence_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c32ef",
   "metadata": {},
   "source": [
    "**b) Implement the forward and backward algorithms and run them on the observed\n",
    "$x$. You should memorize a common factor $u_{t}$ for the $\\alpha_{t}^{k}$ to avoid floating point \n",
    "underflow, since $\\alpha_{t}^{k}$ quickly become very small. The same holds for $\\beta_{t}^{k}$. Report\n",
    "$\\alpha_{135}^{1}/\\alpha_{135}^{2}$ and $\\beta_{135}^{1}/\\beta_{135}^{2}$ where the counting starts from $t = 0$. (3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767ab66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " $\\alpha_{135}^1/\\alpha_{135}^2$="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2359072218169365\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " $\\beta_{135}^1/ \\beta_{135}^2$="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5083264886518888\n"
     ]
    }
   ],
   "source": [
    "def forward_backward(pb, pi, a, b):\n",
    "# Initialize the forward and backward variables\n",
    "    alpha = np.zeros((num_states, T))\n",
    "    beta = np.zeros((num_states, T))\n",
    "\n",
    "    alpha[:, 0] = b[:, pb[0] - 1] * pi\n",
    "    alpha[:, 0] = alpha[:, 0] / alpha[:, 0].sum()\n",
    "\n",
    "    # Forward algorithm\n",
    "    for t in range(1, T):\n",
    "        alpha_num = b[:, pb[t] - 1] * np.sum(a * (alpha[:, t - 1].reshape(-1, 1)), axis=0)\n",
    "        alpha_denom = np.sum(alpha_num)\n",
    "        alpha[:, t] = alpha_num / alpha_denom\n",
    "\n",
    "    # Backward algorithm\n",
    "    beta[:, -1] = 0.5\n",
    "\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        beta_num = np.sum(a * (beta[:, t + 1] * b[:, pb[t + 1] - 1]), axis=1)\n",
    "        beta_denom = np.sum(beta_num)\n",
    "        beta[:, t] = beta_num / beta_denom\n",
    "    \n",
    "    return alpha,beta\n",
    "    \n",
    "\n",
    "# Calculate alpha_135/alpha_135 and beta_135/beta_135\n",
    "t_135 = min(135, T - 1)  # 0-based index\n",
    "alpha, beta = forward_backward(observed_sequence, initial_probabilities, transition_probabilities, emission_probabilities)\n",
    "\n",
    "alpha_ratio = alpha[0][t_135] / alpha[1][t_135]\n",
    "beta_ratio = beta[0][t_135] / beta[1][t_135]\n",
    "\n",
    "# Print the results\n",
    "display_markdown(\" $\\\\alpha_{135}^1/\\\\alpha_{135}^2$=\",raw=True)\n",
    "print(alpha_ratio)\n",
    "display_markdown(\" $\\\\beta_{135}^1/ \\\\beta_{135}^2$=\", raw=True)\n",
    "print(beta_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199a15f",
   "metadata": {},
   "source": [
    "**2) Download the dataset hmm_pb2.csv from Canvas. It represents a sequence of\n",
    "10000 dice rolls x from the Dishonest casino model but with other values for the a and\n",
    "b parameters than those from class. Having so many observations, you are going to\n",
    "learn the model parameters.<br>\n",
    "Implement and run the Baum-Welch algorithm using the forward and backward\n",
    "algorithms that you already implemented for Pb 1. You can initialize the $\\pi, a, b$ with\n",
    "your guess, or with some random probabilities (make sure that π sums to 1 and that\n",
    "$a_{ij} , b_{i}$\n",
    "k sum to 1 for each i). The algorithm converges quite slowly, so you might need\n",
    "to run it for up 1000 iterations or more for the parameters to converge.\n",
    "Report the values of $\\pi, a, b$ that you have obtained. (4 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef7c39c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2,275) (1,2,10000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m gamma\u001b[38;5;241m=\u001b[39m (alpha\u001b[38;5;241m*\u001b[39mbeta)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(alpha\u001b[38;5;241m*\u001b[39mbeta, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Re-estimate a (transition probabilities)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m xi_numerator \u001b[38;5;241m=\u001b[39m \u001b[43malpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_b\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_sequence_pb2\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m xi \u001b[38;5;241m=\u001b[39m xi_numerator \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(xi_numerator, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m new_pi \u001b[38;5;241m=\u001b[39m gamma[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2,275) (1,2,10000) "
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "hmm_pb2_path = Path(r'D:\\Pycharm\\Courses\\STA5635\\HW8\\hmm_pb2.csv')\n",
    "# Load the dataset\n",
    "observed_sequence_pb2 = np.array(pd.read_csv(hmm_pb2_path, header=None)).squeeze()\n",
    "new_pi=initial_probabilities\n",
    "new_a=transition_probabilities\n",
    "new_b=emission_probabilities\n",
    "\n",
    "# Initialize the model parameters π, a, and b with your initial guess or random values\n",
    "num_states = 2  # Number of hidden states (Fair and Loaded)\n",
    "num_symbols = 6  # Number of symbols on the dice\n",
    "\n",
    "T_b = len(observed_sequence_pb2)\n",
    "\n",
    "# Initial guess for b (emission probabilities)\n",
    "encoder = OneHotEncoder(categories = [[1,2,3,4,5,6]], sparse_output=False)\n",
    "encoded_pb = np.transpose(encoder.fit_transform(observed_sequence_pb2.reshape(-1,1)))\n",
    "\n",
    "# Baum-Welch algorithm\n",
    "num_iterations = 100  # You may need to run more iterations for convergence\n",
    "for iteration in range(num_iterations):\n",
    "    # Forward and Backward algorithms to calculate alpha and beta\n",
    "    alpha, beta = forward_backward(observed_sequence_pb2, new_pi, new_a, new_b)\n",
    "\n",
    "    gamma= (alpha*beta)/np.sum(alpha*beta, axis = 0).reshape(1,-1)\n",
    "\n",
    "    # Re-estimate a (transition probabilities)\n",
    "    xi_numerator = alpha.reshape(2, 1, -1) * new_a.reshape(2, 2, 1) * \\\n",
    "            np.roll(beta.reshape(1, 2, -1), shift = -1, axis = -1) * \\\n",
    "            new_b[:, np.roll(observed_sequence_pb2-1,-1)].reshape(1, 2, -1)\n",
    "\n",
    "    xi = xi_numerator / np.sum(xi_numerator, axis=(0,1)).reshape(1,1,-1)\n",
    "    new_pi = gamma[:, 0]\n",
    "    new_a = np.sum(xi[:,:,:-1], axis = 2)/np.sum(gamma[:, :-1], axis = 1).reshape(-1,1)\n",
    "    new_b = np.sum(gamma.reshape(2,1,-1)*encoded_pb.reshape(1,6,-1), axis = 2)/ \\\n",
    "        np.sum(gamma, axis = 1).reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the learned parameters\n",
    "display_markdown(\"The following shows the learned initial probability.\", raw=True)\n",
    "print(new_pi)\n",
    "display_markdown(\"The following shows the learned transition probability.\", raw=True)\n",
    "print(new_a)\n",
    "display_markdown(\"The following shows the learned emission probability.\", raw=True)\n",
    "print(new_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fc678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
